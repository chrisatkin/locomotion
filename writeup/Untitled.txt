\chapter{Results} \label{chp:results}
\section{Introduction} \label{sec:results/introduction}
In this chapter, the results of using Locomotion on the benchmarks presented in section \ref{sec:methodology/params} are presented, along with a critical analysis of the results.

\section{Basic Testing} \label{sec:results/basic}
The first testing that was conduct was to determine the correct operation of the instrumentation and runtime library. Several tests were constructed in order to test at the extremes (for edge cases) of dependency analysis - every access is dependent, and no access is dependent.

	\subsection{No Dependencies} \label{sec:result/basic/no-dep}
	\begin{figure}
			\centering
			\begin{gnuplot}[terminal=pdf]
				load '../dynamic/formatted-results/vector-survey-all/hash-deps.gnuplot'
			\end{gnuplot}
			\caption{Number of dependencies detected versus number of accesses using a hash map}
			\label{chart:all-dep-hash}
		\end{figure}
		
		\begin{figure}
			\centering
			\begin{gnuplot}[terminal=pdf]
				load '../dynamic/formatted-results/vector-survey-all/bloomfilter-deps.gnuplot'
			\end{gnuplot}
			\caption{Number of dependencies detected versus number of accesses using a bloom filter, fpp = 0.03}
			\label{chart:all-dep-bloom}
		\end{figure}
		
		\begin{figure}
			\centering
			\begin{gnuplot}[terminal=pdf]
				load '../dynamic/formatted-results/vector-survey-all/hash-memory.gnuplot'
			\end{gnuplot}
			\caption{Memory usage versus number of accesses using a hash map}
			\label{chart:all-hash-memory}
		\end{figure}
		
		\begin{figure}
			\centering
			\begin{gnuplot}[terminal=pdf]
				load '../dynamic/formatted-results/vector-survey-all/bloomfilter-memory.gnuplot'
			\end{gnuplot}
			\caption{Memory usage versus number of accesses using a bloom filter, fpp = 0.03}
			\label{chart:all-memory-bloom}
		\end{figure}
		
		\begin{figure}
			\centering
			\begin{gnuplot}[terminal=pdf]
				load '../dynamic/formatted-results/vector-survey-all/hash-time.gnuplot'
			\end{gnuplot}
			\caption{Execution time versus number of access using a hash set}
		\end{figure}
		
		\begin{figure}
			\centering
			\begin{gnuplot}[terminal=pdf]
				load '../dynamic/formatted-results/vector-survey-all/bloomfilter-time.gnuplot'
			\end{gnuplot}
			\caption{Execution time versus number of accesses using a bloom filter, fpp = 0.03}
			\label{chart:all-time-bloom}
		\end{figure}
	
	We first consider the case of where no dependencies are detected. We observed the following results for the exact and inexact storage mechanisms as described in section \ref{sec:runtime/storage}. This scenario is shown in order to prove that the instrumentation can detect lack of dependencies, and to highlight the error rate of bloom filters.
	
	The first results that we investigate are the number of dependencies detected when there are none present. This allows us to investigate the properties of the bloom filter.
	
	\begin{figure}
		\centering
		\begin{gnuplot}[terminal=pdf]
			load '../dynamic/formatted-results/vector-survey-none/hash-deps.gnuplot'
		\end{gnuplot}
		\caption{Number of dependencies detected versus number of accesses using a hash map}
		\label{chart:none-dep-hash}
	\end{figure}
	
	In figure \ref{chart:none-dep-hash}, we can see how the number of dependencies detected changes as a function of the number of accesses. As expected, there are no dependencies detected.
	
	\begin{figure}
		\centering
		\begin{gnuplot}[terminal=pdf]
			load '../dynamic/formatted-results/vector-survey-none/bloomfilter-deps.gnuplot'
		\end{gnuplot}
		\caption{Number of dependencies detected versus number of accesses using a bloom filter, fpp = 0.03}
		\label{chart:none-dep-bloom}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{gnuplot}[terminal=pdf]
			load '../dynamic/formatted-results/vector-survey-none/hash-memory.gnuplot'
		\end{gnuplot}
		\caption{Memory usage versus number of accesses using a hash map}
		\label{chart:none-hash-memory}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{gnuplot}[terminal=pdf]
			load '../dynamic/formatted-results/vector-survey-none/bloomfilter-memory.gnuplot'
		\end{gnuplot}
		\caption{Memory usage versus number of accesses using a bloom filter, fpp = 0.03}
		\label{chart:none-memory-bloom}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{gnuplot}[terminal=pdf]
			load '../dynamic/formatted-results/vector-survey-none/hash-time.gnuplot'
		\end{gnuplot}
		\caption{Execution time versus number of access using a hash set}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{gnuplot}[terminal=pdf]
			load '../dynamic/formatted-results/vector-survey-none/bloomfilter-time.gnuplot'
		\end{gnuplot}
		\caption{Execution time versus number of accesses using a bloom filter, fpp = 0.03}
		\label{chart:none-time-bloom}
	\end{figure}
	
	\subsection{All Dependent} \label{sec:result/basic/all-dep}
	Next, the instrumentation is tested when all of the accesses are dependent. In this case, the dependencies are $\delta^{0}$ dependencies, but this does not effect the results.

	We can see here that for both trace formats, the correct number of dependencies are detected. For the bloom filter, this is due to the `no false negative' property - a false negative, in this case, is wrongly reporting that an access has not been seen before.
	
	From figure \ref{chart:all-dependent-memory-comparison}, we can begin to see the results of using a bloom filter. When the memory usage is compared, we notice that the bloom filter is significantly lower.
	
	Additionally, we can see from figures  and \ref{chart:none-dependent-memory-comparison} that the memory usage is virtually identical for both experiments, even though the number of dependencies is at a polar opposite. This is consistent with the space complexity analysis for bloom filters, presented in section \ref{sec:runtime/storage/probabilistic/bloom}. The memory usage does not vary with the number of accesses - again, this is to be expected as the bit vector is of a fixed length.
	
	From these memory usage results we can also begin to understand why memory usage measurement is so difficult in the JVM -- there are several anomalies in both datasets. This is likely due to the unpredictable/non-deterministic nature of the garbage collection algorithm, as well as the OS memory allocation mechanism. However, when we only take into account the non-anomalous results and see the overall trends, we see a clear pattern already -- bloom filters offer a significant memory usage improvement over sets.
	
	Next, we consider the execution time overhead of using exact versus inexact approaches. Details of the methodology used to measure the time difference can be found in section \ref{sec:methodology/measurements/time}.
	
	We can see from figure \ref{chart:all-dependent-time-comparison} that bloom filters do, in some cases, have a higher execution time than hash sets. This is likely as a result of the aforementioned (section \ref{sec:runtime/implementation/trace/bloom}) $T_{lookup}^{bloom}=O(k)$ lookup time.
	
	However, for a thorough analysis we must consider the implementation of the bloom filter used. The implementation used is from Google Guava, which uses an innovative technique presented by \citet{Azar2006} who show that instead of $T_{lookup}^{blook}=O(k)$, it is possible to instead use a 2-family of universal hash functions instead, without an asymptotic loss in false positive probability. The time complexity of universal hash functions for hashing $n$-bit strings to $m$-bit strings has been shown to be $T_{uh}=\Omega(mn)$ \citep{Mansour1990}\footnote{Note that it is possible to achieve a $T_p=\Omega(log n)$ parallel implementation of universal hashing using CREW PRAM architecture. However, this is not likely to have a significant performance improvement.}.
	
	Although this is a performance improvement (from $T_{lookup}^{bloom}=O(k)$ to $T_{lookup}^{bloom}=\Omega(mn)$), there are still constants to be considered. An optimal hash map implementation (\ie, one with an adequate load factor and capacity) requires a single hash, and the hash is in-fact $T=O(1)$, whereas the bloom filter requires two $T=\Omega(mn)$ hashes. This is the likely cause of the slightly slower performance of the bloom-filter implementation. 
	
	The result for bloom filter with a bit vector length of 100 using 1000 accesses is considered to be an anomaly. Although the other results for a length 100 bit vector do show increases on time, there appears to be no correlation between number of accesses and execution time when the bit vector is 100 in length. Regardless, as we shall see in later sections, a length 100 bit vector results in a large dependency detection rate ($\epsilon_{\delta}$), and are therefore unsuitable for dependency analysis algorithms.
	
	The cause of the unexpected (\ie, non-linear) execution time for the hash set is likely an sub-optimal load factor. Later, we will investigate the effects of modifying this, as well as the expected number of insertions.
	
	In these experiments, we used a fixed $ffp$ of 0.03. In later experiments, this value will be modified in order to determine the optimal configuration for the bloom filter.

\section{Parametric} \label{sec:results/parametric}
The parametric tests are described thoroughly in chapter \ref{chp:parametric}.

The first experiments that we ran with the parametric benchmark were constant numbers of dependencies. The number of dependencies was constant at 900.

As we can see in figure \ref{chart:fractional-constant-900-hashset}, the number of dependencies is a constant 900 for all accesses lengths. Naturally, this is expected.

\section{N-Body} \label{sec:results/nbody}

\section{Overhead} \label{sec:results/overhead}
	\subsection{Execution Time} \label{sec:results/overhead/time}
	
	\subsection{Memory Usage} \label{sec:results/overhead/memory}

\section{Analysis} \label{sec:results/analysis}

\section{Summary} \label{sec:results/summary}