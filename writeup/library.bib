Automatically generated by Mendeley 1.9.1
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Anderson2013,
abstract = {Papers on functional language implementations frequently set the goal of achieving performance “comparable to C”, and sometimes report results comparing benchmark results to concrete C imple- mentations of the same problem. A key pair of questions for such comparisons is: what C program to compare to, and what C com- piler to compare with? In a 2012 paper, Satish et al [9] compare naive serial C implementations of a range of throughput-oriented benchmarks to best-optimized implementations parallelized on a six-core machine and demonstrate an average 23× (up to 53×) speedup. Further, they demonstrate that most of this so-called “Ninja-gap” between naive C and best-optimized code can be elim- inated using relatively straightforward C programming techniques. Even accounting for thread parallel speedup, these results demon- strate a substantial performance gap between naive and tuned C code. In this paper we choose a subset of the benchmarks studied by Satish et al to port to Haskell. We measure performance of these Haskell benchmarks compiled with the standard Glasgow Haskell Compiler and with our experimental Intel Labs Haskell Research Compiler and report results as compared to our best reconstruc- tions of the algorithms used by Satish et al. Results are reported as measured both on an Intel Xeon E5-4650 32-core machine, and on an Intel Xeon Phi co-processor. We hope that this study provides valuable data on the concrete performance of Haskell relative to C.},
author = {Anderson, Todd A and Petersen, Leaf and Lui, Hai and Glew, Neal},
file = {:afs/inf.ed.ac.uk/user/s12/s1255753/Documents/\_mendeley/Anderson et al/Unknown/Anderson et al. - 2013 - Measuring the Haskell Gap - Unknown.pdf:pdf},
pages = {1--12},
title = {{Measuring the Haskell Gap}},
url = {http://www.leafpetersen.com/leaf/publications/hs2013/haskell-gap.pdf},
year = {2013}
}
@inproceedings{Orchard2010,
abstract = {A fully automatic, compiler-driven approach to parallelisation can result in unpredictable time and space costs for compiled code. On the other hand, a fully manual approach to parallelisation can be long, tedious, prone to errors, hard to debug, and often architecture- specific. We present a declarative domain-specific language, Yp- nos, for expressing structured grid computations which encourages manual specification of causally sequential operations but then al- lows a simple, predictable, static analysis to generate optimised, parallel implementations. We introduce the language and provide some discussion on the theoretical aspects of the language seman- tics, particularly the structuring of computations around the cate- gory theoretic notion of a comonad.},
address = {New York, New York, USA},
author = {Orchard, Dominic A. and Bolingbroke, Max and Mycroft, Alan},
booktitle = {Proceedings of the 5th ACM SIGPLAN workshop on Declarative aspects of multicore programming - DAMP '10},
doi = {10.1145/1708046.1708053},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Orchard, Bolingbroke, Mycroft - 2010 - Ypnos.pdf:pdf},
isbn = {9781605588599},
keywords = {comonads,edsl,parallelism,stencils,structured grids,ypnos},
month = jan,
pages = {15},
publisher = {ACM Press},
title = {{Ypnos}},
url = {http://dl.acm.org/citation.cfm?id=1708046.1708053 http://portal.acm.org/citation.cfm?doid=1708046.1708053},
year = {2010}
}
@techreport{Constantinides2004,
abstract = {In his famous letter Go To statement considered harmful Dijkstra started a discussion finally resulting in banning of most unstructured control flow statements from modern high level programming languages. To overcome limitations of todays programming languages, aspect oriented programming has been proposed. Unfortunately language elements used by many AO languages are in a way similar to the Go To statment, so we ask the provocative: AOP considered harmful?},
author = {Constantinides, C and Skotiniotis, T and Stoerzer, M},
booktitle = {1 st European Interactive Workshop on Aspect Systems EIWAS},
institution = {Concordia University},
title = {{AOP considered harmful}},
url = {http://pp.info.uni-karlsruhe.de/uploads/publikationen/constantinides04eiwas.pdf},
year = {2004}
}
@article{Patt1997,
abstract = {Billion-transistor processors will be much as they are today, just bigger, faster and wider (issuing more instructions at once). The authors describe the key problems (instruction supply, data memory supply and an implementable execution core) that prevent current superscalar computers from scaling up to 16- or 32-instructions per issue. They propose using out-of-order fetching, multi-hybrid branch predictors and trace caches to improve the instruction supply. They predict that replicated first-level caches, huge on-chip caches and data value speculation will enhance the data supply. To provide a high-speed, implementable execution core that is capable of sustaining the necessary instruction throughput, they advocate a large, out-of-order-issue instruction window (2,000 instructions), clustered (separated) banks of functional units and hierarchical scheduling of ready instructions. They contend that the current uniprocessor model can provide sufficient performance and use a billion transistors effectively without changing the programming model or discarding software compatibility},
author = {Patt, Y.N. and Patel, S.J. and Evers, M. and Friendly, D.H. and Stark, J.},
doi = {10.1109/2.612249},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Patt et al. - 1997 - One billion transistors, one uniprocessor, one chip.html:html},
issn = {00189162},
journal = {Computer},
number = {9},
pages = {51--57},
title = {{One billion transistors, one uniprocessor, one chip}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=612249},
volume = {30},
year = {1997}
}
@article{Grossman2011,
abstract = {The computer industry is at a major inflection point in its hardware roadmap due to the end of a decades-long trend of exponentially increasing clock frequencies. Instead, future computer systems are expected to be built using homogeneous and heterogeneous many-core processors with 10's to 100's of cores per chip, and complex hardware designs to address the challenges of concurrency, energy efficiency and resiliency. Unlike previous generations of hardware evolution, this shift towards many-core computing will have a profound impact on software. These software challenges are further compounded by the need to enable parallelism in workloads and application domains that traditionally did not have to worry about multiprocessor parallelism in the past. A recent trend in mainstream desktop systems is the use of graphics processor units (GPUs) to obtain order-of-magnitude performance improvements relative to general-purpose CPUs. Unfortunately, hybrid programming models that support multithreaded execution on CPUs in parallel with CUDA execution on GPUs prove to be too complex for use by mainstream programmers and domain experts, especially when targeting platforms with multiple CPU cores and multiple GPU devices. In this paper, we extend past work on Intel's Concurrent Collections (CnC) programming model to address the hybrid programming challenge using a model called CnC-CUDA. CnC is a declarative and implicitly parallel coordination language that supports flexible combinations of task and data parallelism while retaining determinism. CnC computations are built using steps that are related by data and control dependence edges, which are represented by a CnC graph. The CnC-CUDA extensions in this paper include the definition of multithreaded steps for execution on GPUs, and automatic generation of data and control flow between CPU steps and GPU steps. Experimental results show that this approach can yield significant performance benefits with both GPU execution and hybrid CPU/GPU execution. 2011 Springer-Verlag Berlin Heidelberg.},
author = {Grossman, M and {Simion Sb\^{\i}rlea}, A and Budimli\'{c}, Z and Sarkar, V},
journal = {Lecture Notes in Computer Science including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics},
pages = {230--245},
title = {{CnC-CUDA: Declarative programming for GPUs}},
volume = {6548 LNCS},
year = {2011}
}
@article{Backus1979,
abstract = {This article discusses attitudes about "automatic programming," the economics of programming, and existing programming systems, all in the early 1950s. It describes the formation of the FORTRAN group, its knowledge of existing systems, its plans for FORTRAN, and the development of the language in 1954. It describes the development of the optimizing compiler for FORTRAN I, of various language manuals, and of FORTRAN II and III. It concludes with remarks about later developments and the impact of FORTRAN and its successors on programming today.},
author = {Backus, John},
doi = {10.1109/MAHC.1979.10013},
issn = {1058-6180},
journal = {IEEE Annals of the History of Computing},
month = jan,
number = {1},
pages = {21--37},
title = {{The History of FORTRAN I, II and III}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4392880},
volume = {1},
year = {1979}
}
@book{Cole,
abstract = {In the past, most significant improvements in computer performance have been achieved as a result of advances in simple device technology. The introduction of large scale parallelism at the inter-processor level now represents a viable alter- native. However, this method also introduces new difficulties, most notably the conceptual barrier encountered by the user of such a system in efficiently coor- dinating many concurrent activities towards a single goal. Thus, the design and implementation of software systems which can ease this burden is of increasing importance. Such a system must find a good balance between the simplicity of the interface presented and the efficiency with which it can be implemented. This book considers existing work in the area and proposes a new approach. The new system presents the user with a selection of independent “algorithmic skeletons”, each of which describes the structure of a particular style of algorithm, in the way in which “higher order functions” represent general computational frameworks in the context of functional programming languages. The user must describe a solution to a problem as an instance of the appropriate skeleton. The implementation task is simplified by the fact that each skeleton may be considered independently, in contrast to the monolithic programming interfaces of existing systems at a similar level of abstraction. The four skeletons presented here are based on the notions of “fixed degree di- vide and conquer”, “iterative combination” “clustering” and “task queues”. Each skeleton is introduced in terms of the abstraction it presents to the user. Imple- mentation on a square grid of autonomous processor-memory pairs is considered, and examples of problems which could be solved in terms of the skeleton are presented. In conclusion, the strengths and weaknesses of the “skeletal” approach are assessed in the context of the existing alternatives.},
address = {Edinburgh},
author = {Cole, Murray},
edition = {First},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Cole - 1989 - Algorithmic Skeletons Structured Management of Parallel Computation Table of Contents.pdf:pdf},
publisher = {MIT Press},
title = {{Algorithmic Skeletons : Structured Management of Parallel Computation Table of Contents}},
url = {http://homepages.inf.ed.ac.uk/mic/Pubs/skeletonbook.pdf},
year = {1989}
}
@misc{XeonPhi,
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Intel® Xeon Phi™ Coprocessor Parallel Processing.html:html},
keywords = {croprocessors,inte xeon processors,intel xeon phi coprocessors,xeon phi},
title = {{Intel® Xeon Phi™ Coprocessor: Parallel Processing}},
url = {http://www.intel.ru/content/www/us/en/high-performance-computing/high-performance-xeon-phi-coprocessor-brief.html},
urldate = {29/01/13}
}
@article{Ogata2010,
author = {Ogata, Kazunori and Mikurube, Dai and Kawachiya, Kiyokuni and Trent, Scott and Onodera, Tamiya},
doi = {10.1145/1932682.1869477},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Ogata et al. - 2010 - A study of Java's non-Java memory.pdf:pdf},
isbn = {978-1-4503-0203-6},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {java,java native memory,memory footprint analysis,non-java memory},
month = oct,
number = {10},
pages = {191},
publisher = {ACM},
title = {{A study of Java's non-Java memory}},
url = {http://dl.acm.org/citation.cfm?id=1932682.1869477},
volume = {45},
year = {2010}
}
@book{DatabasesBook,
author = {Garcia-Molina, Hector and Ullman, Jeffrey D. and Widom, Jennifer},
edition = {First},
isbn = {0-13-031995-3},
publisher = {Prentice Hall},
title = {{Database Systems: The Complete Book}},
year = {2002}
}
@techreport{Fraser04,
address = {Cambridge},
author = {Fraser, Keir},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Fraser - 2004 - Technical Report.pdf:pdf},
institution = {University of Cambridge},
number = {579},
title = {{Technical Report}},
url = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-579.pdf},
year = {2004}
}
@inproceedings{Holk2011,
abstract = {The recent rise in the popularity of Graphics Processing Units (GPUs) has been fueled by software frameworks, such as NVIDIA’s Compute Unified De- vice Architecture (CUDA) and Khronos Group’s OpenCL that make GPUs avail- able for general purpose computing. However, CUDA and OpenCL are still low- level approaches that require users to handle details about data layout and move- ment across levels of memory hierarchy. We propose a declarative approach to coordinating computation and data movement between CPU and GPU, through a domain-specific language that we called Harlan. Not only does a declarative lan- guage obviate the need for the programmer to write low-level error-prone boiler- plate code, by raising the abstraction of specifying GPU computation it also allows the compiler to optimize data movement and overlap between CPU and GPU com- putation. By focusing on the “what”, and not the “how”, of data layout, data move- ment, and computation scheduling, the language eliminates the sources of many programming errors related to correctness and performance.},
address = {Bloomington},
author = {Holk, E and Byrd, WE and Mahajan, Nilesh and Willcock, Jeremiah},
booktitle = {Parallel Computing},
editor = {Boss, Deschere and D'hollander, Erik H. and Joubert, Gerhard R. and Padua, David and Peters, Frans and Sawyer, Mark},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Holk et al. - 2011 - Declarative Parallel Programming for GPUs.pdf:pdf},
keywords = {compilers,declarative parallel programming,gpgpus},
pages = {297--304},
publisher = {IOS Press},
title = {{Declarative Parallel Programming for GPUs.}},
url = {http://osl.iu.edu/publications/prints/2011/2011-parco-holk-harlan.pdf},
volume = {22},
year = {2011}
}
@article{Chen2007,
abstract = {Join points and advices are two fundamental constructs of aspect-oriented programming languages. AspectJ provides a large set of useful pointcuts that enables aspect-oriented programmers to pick out target join points for advice weaving in a highly flexible manner. However, the field access pointcuts of AspectJ do not support array objects in full. When an element of an array field is set or referenced, the corresponding index values and assigned value are not exposed to the advice. This paper presents an extension of AspectJ’s field access pointcuts to arrays that exposes such useful context information. We have implemented this extension using the abc compiler for AspectJ. The core of our implementation is a finite-state machine based pointcut matcher that can handle arrays of multiple dimensions in a uniform way.},
author = {Chen, Kung and Chien, Chin-hung},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Chen, Chien - 2007 - Extending the Field Access Pointcuts of AspectJ to Arrays.pdf:pdf},
journal = {Journal of Software Engineering Studies},
number = {2},
pages = {2--11},
title = {{Extending the Field Access Pointcuts of AspectJ to Arrays}},
url = {http://www.geocities.ws/m8809301/pub/JSESv2n2\_KungChen\_970214.pdf},
volume = {2},
year = {2007}
}
@article{Swamidass2007,
abstract = {In many modern chemoinformatics systems, molecules are represented by long binary fingerprint vectors recording the presence or absence of particular features or substructures, such as labeled paths or trees, in the molecular graphs. These long fingerprints are often compressed to much shorter fingerprints using a simple modulo operation. As the length of the fingerprints decreases, their typical density and overlap tend to increase, and so does any similarity measure based on overlap, such as the widely used Tanimoto similarity. Here we show that this correlation between shorter fingerprints and higher similarity can be thought of as a systematic error introduced by the fingerprint folding algorithm and that this systematic error can be corrected mathematically. More precisely, given two molecules and their compressed fingerprints of a given length, we show how a better estimate of their uncompressed overlap, hence of their similarity, can be derived to correct for this bias. We show how the correction can be implemented not only for the Tanimoto measure but also for all other commonly used measures. Experiments on various data sets and fingerprint sizes demonstrate how, with a negligible computational overhead, the correction noticeably improves the sensitivity and specificity of chemical retrieval.},
author = {Swamidass, S Joshua and Baldi, Pierre},
doi = {10.1021/ci600526a},
issn = {1549-9596},
journal = {Journal of chemical information and modeling},
keywords = {Chemistry,Chemistry: methods,Databases,Factual,Informatics,Informatics: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Mathematics},
number = {3},
pages = {952--64},
pmid = {17444629},
title = {{Mathematical correction for fingerprint similarity measures to improve chemical retrieval.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17444629},
volume = {47},
year = {2007}
}
@inproceedings{Hofstee,
abstract = {This paper provides a background and rationale for some of the architecture and design decisions in the cell processor, a processor optimized for compute-intensive and broadband rich media applications, jointly developed by Sony Group, Toshiba, and IBM. The paper discusses some of the challenges microprocessor designers face and provides motivation for performance per transistor as a reasonable first-order metric for design efficiency. Common microarchitectural enhancements relative to this metric are provided. Also alternate architectural choices and some of its limitations are discussed and non-homogeneous SMP as a means to overcome these limitations is proposed.},
author = {Hofstee, H.P.},
booktitle = {11th International Symposium on High-Performance Computer Architecture},
doi = {10.1109/HPCA.2005.26},
isbn = {0-7695-2275-0},
pages = {258--262},
publisher = {IEEE},
title = {{Power Efficient Processor Architecture and The Cell Processor}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1385948}
}
@inproceedings{Rogers2005,
abstract = {Increasing the number of instructions executing in parallel has helped improve processor performance, but the technique is limited. Executing code on parallel threads and processors has fewer limitations, but most computer programs tend to be serial in nature. This paper presents a compiler optimisation that at run-time parallelises code inside a JVM and thereby increases the number of threads. We show Spec JVM benchmark results for this optimisation. The performance on a current desktop processor is slower than without parallel threads, caused by thread creation costs, but with these costs removed the performance is better than the serial code. We measure the threading costs and discuss how a future computer architecture will enable this optimisation to be feasible in exploiting thread instead of instruction and/or vector parallelism.},
author = {Rogers, I. and Kirkham, C. and Watson, I.},
booktitle = {Sixth International Conference on Parallel and Distributed Computing Applications and Technologies (PDCAT'05)},
doi = {10.1109/PDCAT.2005.164},
isbn = {0-7695-2405-2},
pages = {35--39},
publisher = {IEEE},
title = {{Loop Parallelisation for the Jikes RVM}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1578860},
year = {2005}
}
@book{Gamma1995,
abstract = {Capturing a wealth of experience about the design of object-oriented software, four top-notch designers present a catalog of simple and succinct solutions to commonly occurring design problems. Previously undocumented, these 23 patterns allow designers to create more flexible, elegant, and ultimately reusable designs without having to rediscover the design solutions themselves. The authors begin by describing what patterns are and how they can help you design object-oriented software. They then go on to systematically name, explain, evaluate, and catalog recurring designs in object-oriented systems. With Design Patterns as your guide, you will learn how these important patterns fit into the software development process, and how you can leverage them to solve your own design problems most efficiently. Each pattern describes the circumstances in which it is applicable, when it can be applied in view of other design constraints, and the consequences and trade-offs of using the pattern within a larger design. All patterns are compiled from real systems and are based on real-world examples. Each pattern also includes code that demonstrates how it may be implemented in object-oriented programming languages like C++ or Smalltalk. 0201633612B07092001},
author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
booktitle = {Design},
doi = {10.1093/carcin/bgs084},
file = {:afs/inf.ed.ac.uk/user/s12/s1255753/Documents/\_mendeley/Gamma et al/Design/Gamma et al. - 1995 - Design Patterns Elements of Reusable Object-Oriented Software - Design.pdf:pdf},
isbn = {0201633612},
issn = {02016361},
keywords = {computacao (metodologia e tecnicas) |2 larpcal,gang of four,gof,pattern},
mendeley-tags = {computacao (metodologia e tecnicas) |2 larpcal,gang of four,gof,pattern},
pages = {395},
pmid = {22693012},
title = {{Design Patterns: Elements of Reusable Object-Oriented Software}},
volume = {206},
year = {1995}
}
@article{Kiczales2001,
abstract = {AspectJ is a simple and practical aspect-oriented extension to Java.. With just a few new constructs, AspectJ provides support for modular implementation of a range of crosscutting concerns. In AspectJs dynamic join point model, join points are well-defined points in the execution of the program; pointcuts are collections of join points; advice are special method-like constructs that can be attached to pointcuts; and aspects are modular units of crosscutting implementation, comprising pointcuts, advice, and ordinary Java member declarations. AspectJ code is compiled into standard Java bytecode. Simple extensions to existing Java development environments make it possible to browse the crosscutting structure of aspects in the same kind of way as one browses the inheritance structure of classes. Several examples show that AspectJ is powerful, and that programs written using it are easy to understand.},
author = {Kiczales, Gregor and Hilsdale, Erik and Hugunin, Jim and Kersten, Mik and Palm, Jeffrey and Griswold, William G},
doi = {10.1007/3-540-45337-7\_18},
isbn = {3540422064},
issn = {03029743},
journal = {Main},
pages = {327--353},
title = {{An Overview of AspectJ}},
url = {http://www.cs.ubc.ca/~kdvolder/binaries/aspectj-overview.pdf},
volume = {2072},
year = {2001}
}
@article{Kim2000,
author = {Kim, Jin-Soo and Hsu, Yarsun},
doi = {10.1145/345063.339422},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Kim, Hsu - 2000 - Memory system behavior of Java programs.pdf:pdf},
isbn = {1-58113-194-1},
issn = {01635999},
journal = {ACM SIGMETRICS Performance Evaluation Review},
month = jun,
number = {1},
pages = {264--274},
publisher = {ACM},
title = {{Memory system behavior of Java programs}},
url = {http://dl.acm.org/citation.cfm?id=345063.339422},
volume = {28},
year = {2000}
}
@article{Franz2008,
author = {Franz, Michael},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Franz - 2008 - Dynamic Parallelization and Vectorization of Binary Executables on Hierarchical Platforms.pdf:pdf},
pages = {1--24},
title = {{Dynamic Parallelization and Vectorization of Binary Executables on Hierarchical Platforms}},
volume = {10},
year = {2008}
}
@article{Tournavitis2009,
author = {Tournavitis, Georgios and Wang, Zheng and Franke, Bj\"{o}rn and O'Boyle, Michael F.P.},
doi = {10.1145/1543135.1542496},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Tournavitis et al. - 2009 - Towards a holistic approach to auto-parallelization.pdf:pdf},
isbn = {978-1-60558-392-1},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {auto-parallelization,machine-learning based parallelism mapping,openmp,profile-driven parallelism detection},
month = may,
number = {6},
pages = {177},
title = {{Towards a holistic approach to auto-parallelization}},
url = {http://dl.acm.org/citation.cfm?id=1543135.1542496},
volume = {44},
year = {2009}
}
@techreport{Atkin2012,
address = {Keele},
author = {Atkin-Granville, Christopher Edward},
institution = {University of Keele},
title = {{Visual Cues for CT Image Segmentation}},
year = {2012}
}
@article{Dong,
author = {Dong, Guoxing and Chen, Kai and Zhu, Erzhou and Zhang, Yichao and Qi, Zhengwei and Guan, Haibing},
doi = {10.1109/PAAP.2010.53},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Dong et al. - Unknown - A Translation Framework for Virtual Execution Environment on CPU GPU Architecture.pdf:pdf},
isbn = {9780769543123},
keywords = {-gpgpu,cuda,parallelization,translator},
title = {{A Translation Framework for Virtual Execution Environment on CPU / GPU Architecture}}
}
@misc{ppls,
address = {Edinburgh},
author = {Cole, Murray},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Cole - 2013 - Parallel Programming Languages and Systems.pdf:pdf},
publisher = {University of Edinburgh},
title = {{Parallel Programming Languages and Systems}},
url = {http://www.inf.ed.ac.uk/teaching/courses/ppls/pplsslides.pdf},
year = {2013}
}
@article{Raman2012,
author = {Raman, Raghavan and Zhao, Jisheng and Sarkar, Vivek and Vechev, Martin and Yahav, Eran},
doi = {10.1145/2345156.2254127},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Raman et al. - 2012 - Scalable and precise dynamic datarace detection for structured parallelism.pdf:pdf},
isbn = {978-1-4503-1205-9},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {data races,parallelism,program analysis},
month = aug,
number = {6},
pages = {531--531--542--542},
publisher = {ACM},
title = {{Scalable and precise dynamic datarace detection for structured parallelism}},
url = {http://dl.acm.org/citation.cfm?id=2345156.2254127},
volume = {47},
year = {2012}
}
@inproceedings{Herlihy1993,
abstract = {A shared data structure is lock-free if its operations do not require mutual exclusion. If one process is interrupted in the middle of an operation, other processes will not be prevented from operating on that object. In highly concurrent systems, lock-free data structures avoid common problems associated with conventional locking techniques, including priority inversion, convoying, and difficulty of avoiding deadlock. This paper introduces transactional memory, a new multiprocessor architecture intended to make lock-free synchronization as efficient (and easy to use) as conventional techniques based on mutual exclusion. Transactional memory allows programmers to define customized read-modify-write operations that apply to multiple, independently-chosen words of memory. It is implemented by straightforward extensions to any multiprocessor cache-coherence protocol. Simulation results show that transactional memory matches or outperforms the best known locking techniques for simple benchmarks, even in the absence of priority inversion, convoying, and deadlock.},
author = {Herlihy, M and Eliot, J and Moss, B},
booktitle = {Proceedings of the 20th Annual International Symposium on Computer Architecture},
doi = {10.1109/ISCA.1993.698569},
isbn = {0-8186-3810-9},
keywords = {memory},
mendeley-tags = {memory},
pages = {289--300},
publisher = {IEEE Comput. Soc. Press},
title = {{Transactional Memory: Architectural Support For Lock-free Data Structures}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=698569},
volume = {21},
year = {1993}
}
@misc{Graal,
author = {Oracle and OpenJDK},
title = {{Graal Project}},
url = {http://openjdk.java.net/projects/graal/},
urldate = {26/07/2013}
}
@article{Ketterlin,
author = {Ketterlin, Alain and Clauss, Philippe},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Ketterlin, Clauss - Unknown - Transparent Parallelization of Binary Code.pdf:pdf},
keywords = {binary code,polytope model,static parallelization},
title = {{Transparent Parallelization of Binary Code}}
}
@inproceedings{Sanchez2007,
abstract = {Transactional Memory (TM) systems must track the read and write sets - items read and written during a transaction - to detect conflicts among concurrent transactions. Several TMs use signatures, which summarize unbounded read/write sets in bounded hardware at a performance cost of false positives (conflicts detected when none exists). This paper examines different organizations to achieve hardware-efficient and accurate TM signatures. First, we find that implementing each signature with a single k-hash- function Bloom filter (True Bloom signature) is inefficient, as it requires multi-ported SRAMs. Instead, we advocate using k single-hash-function Bloom filters in parallel (Parallel Bloom signature), using area-efficient single-ported SRAMs. Our formal analysis shows that both organizations perform equally well in theory and our simulation- based evaluation shows this to hold approximately in practice. We also show that by choosing high-quality hash functions we can achieve signature designs noticeably more accurate than the previously proposed implementations. Finally, we adapt Pagh and Rodler's cuckoo hashing to implement Cuckoo-Bloom signatures. While this representation does not support set intersection, it mitigates false positives for the common case of small read/write sets and performs like a Bloom filter for large sets.},
author = {Sanchez, Daniel and Yen, Luke and Hill, Mark D. and Sankaralingam, Karthikeyan},
booktitle = {40th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2007)},
doi = {10.1109/MICRO.2007.24},
isbn = {0-7695-3047-8},
pages = {123--133},
publisher = {IEEE},
title = {{Implementing Signatures for Transactional Memory}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4408250},
year = {2007}
}
@misc{Yang1997,
abstract = {Equijoin between two relations is one of the basic operations in relational database and a large volume of research have been devoted to it. However, in recent years, there hasn't been a survey which objectively compares a wide spectrum of various join techniques in their relative performances. This survey compares performance and practicality between various join techniques. Main criteria for performance comparisons are disk I/Os. For comparing of practicality, criteria used are easiness and flexibility of implementation. When comparing join techniques, each join technique is evaluated in its full potential, which means that if other techniques are available to enhance this join technique while retaining the main philosophy of it, the later techniques are applied. The main contribution of the paper is that it confirms the believe that no dramatical performance improvement of three major join techniques (nested loops, sort-based, and hash based) of relational database can},
author = {Yang, Yuping and Singhal, Mukesh},
booktitle = {Main},
keywords = {band join,centralized,equijoin,join,join index,join methods,monoobjective,one-shot,optimization,query execution,relational,relational database,survey},
mendeley-tags = {centralized,join methods,monoobjective,one-shot,optimization,relational,survey},
title = {{A comprehensive survey of join techniques in relational databases}},
year = {1997}
}
@inproceedings{Liu2011,
address = {New York, New York, USA},
author = {Liu, Tongping and Curtsinger, Charlie and Berger, Emery D.},
booktitle = {Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles - SOSP '11},
doi = {10.1145/2043556.2043587},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Liu, Curtsinger, Berger - 2011 - Dthreads.pdf:pdf},
isbn = {9781450309776},
month = oct,
pages = {327},
publisher = {ACM Press},
title = {{Dthreads}},
url = {http://dl.acm.org/citation.cfm?id=2043556.2043587},
year = {2011}
}
@article{Stone1991,
abstract = {Some of the technology that will drive the advances of the 1990s are explored. A brief tutorial is given to explain the fundamental speed limits of metal interconnections. The advantages and disadvantages of optical interconnections and where they may be used are discussed in some detail. Trends in speeding up performance by increasing data-path width and by increasing the number of operations performed are reviewed, and questions of efficiency are examined. The advent of super reliable machines produced at very low cost by replicating entire processors is examined.},
author = {Stone, H.S. and Cocke, J.},
doi = {10.1109/2.84897},
issn = {0018-9162},
journal = {Computer},
month = sep,
number = {9},
pages = {30--38},
title = {{Computer architecture in the 1990s}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=84897},
volume = {24},
year = {1991}
}
@inproceedings{Harbulot2005,
abstract = {The current AspectJ join points represent locations in the code that are the interface of the Java objects. However, not all the "things that happen" happen at the interfaces. In particular, loops are a key place that could be advised for parallelisation. This article presents a loop join point model, which allows AspectJ to intervene directly in loops. More generally, this demonstrates the need for, and provides, a more complex join point in AspectJ.The approach used for recognising loops is based on a control-flow analysis at the bytecode level; this avoids ambiguities due to alternative forms of source-code that would effectively produce identical loops. This model is also enhanced with a mechanism for context exposure, which is pivotal for giving a meaning to the use of this join point, and with additional information through join point reflection. The context exposure is particularly useful for writing pointcuts that select specific loops only, and the problem of loop selection is also presented in the paper.Finally, LoopsAJ, an extension for the abc compiler that provides AspectJ with a loop join point, is presented. It is shown how to use this extension for writing aspects that parallelise loops.},
author = {Harbulot, Bruno and Gurd, John R},
booktitle = {Computer},
doi = {10.1145/1119655.1119666},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Harbulot, Gurd - 2005 - A join point for loops in AspectJ.pdf:pdf},
isbn = {159593300X},
pages = {63--74},
title = {{A join point for loops in AspectJ}},
year = {2005}
}
@article{Bruneton2002,
abstract = {ASM is a Java class manipulation tool designed to dynamically generate and manipulate Java classes, which are useful techniques to implement adaptable systems. ASM is based on a new approach, compared to equivalent existing tools, which consists in using the \&quot;visitor\&quot; design pattern without explicitly representing the visited tree with objects. This new approach gives much better performances than those of existing tools, for most of practical needs.},
author = {Bruneton, Eric and Lenglet, Romain and Coupaye, Thierry},
doi = {10.1.1.117.5769},
journal = {Adaptable and extensible component systems},
keywords = {adaptability,adaptabilit\'{e},class,classe,code,dynamic,dynamique,g\'{e}n\'{e}ration,java,transformation,visiteur,visitor},
title = {{ASM: a code manipulation tool to implement adaptable systems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.117.5769},
volume = {30},
year = {2002}
}
@article{Wang2009,
author = {Wang, Cheng and Wu, Youfeng and Borin, Edson and Hu, Shiliang and Liu, Wei and Sager, Dave and Ngai, Tin-fook and Fang, Jesse},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Wang et al. - 2009 - Dynamic Parallelization of Single-Threaded Binary Programs using Speculative Slicing.pdf:pdf},
isbn = {9781605584980},
title = {{Dynamic Parallelization of Single-Threaded Binary Programs using Speculative Slicing}},
year = {2009}
}
@misc{RuntimeDocs,
author = {{Oracle Inc}},
booktitle = {Java 7 documentation},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Oracle Inc - Unknown - Runtime (Java Platform SE 7).html:html},
title = {{Runtime (Java Platform SE 7)}},
url = {http://docs.oracle.com/javase/7/docs/api/java/lang/Runtime.html},
urldate = {25/07/13}
}
@inproceedings{Marek2012,
address = {New York, New York, USA},
author = {Marek, Luk\'{a}\v{s} and Villaz\'{o}n, Alex and Zheng, Yudi and Ansaloni, Danilo and Binder, Walter and Qi, Zhengwei},
booktitle = {Proceedings of the 11th annual international conference on Aspect-oriented Software Development - AOSD '12},
doi = {10.1145/2162049.2162077},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Marek et al. - 2012 - DiSL.pdf:pdf},
isbn = {9781450310925},
keywords = {JVM,aspect-oriented programming,bytecode instrumentation,dynamic program analysis},
month = mar,
pages = {239},
publisher = {ACM Press},
title = {{DiSL}},
url = {http://dl.acm.org/citation.cfm?id=2162049.2162077},
year = {2012}
}
@misc{RoslynProject,
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Roslyn Project.html:html},
keywords = {C\#,CSharp,CTP,Roslyn,VB,Visual Basic},
title = {{Roslyn Project}},
url = {https://www.microsoft.com/en-us/download/details.aspx?id=27744},
urldate = {11/04/13}
}
@techreport{JVMSpec,
address = {Redwood City},
author = {Lindholm, Tim and Buckley, Alex and Bracha, Gilad and Yellin, Frank},
file = {:afs/inf.ed.ac.uk/user/s12/s1255753/Documents/\_mendeley/Lindholm et al/Unknown/Lindholm et al. - 2013 - The Java Virtual Machine Specification Java SE 7 Edition - Unknown.pdf:pdf},
institution = {Oracle, Inc},
title = {{The Java Virtual Machine Specification Java SE 7 Edition}},
url = {http://docs.oracle.com/javase/specs/jvms/se7/jvms7.pdf},
year = {2013}
}
@article{Bloom1970,
author = {Bloom, Burton H.},
doi = {10.1145/362686.362692},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Bloom - 1970 - Spacetime trade-offs in hash coding with allowable errors.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {hash addressing,hash coding,retrieval efficiency,retrieval trade-offs,scatter storage,searching,storage efficiency,storage layout},
month = jul,
number = {7},
pages = {422--426},
publisher = {ACM},
title = {{Space/time trade-offs in hash coding with allowable errors}},
url = {http://dl.acm.org/citation.cfm?id=362686.362692},
volume = {13},
year = {1970}
}
@misc{javaagents,
author = {Javabeats.com},
title = {{Introduction to Java Agents}},
url = {http://www.javabeat.net/2012/06/introduction-to-java-agents/}
}
@article{Yang2011,
author = {Yang, Jing and Skadron, Kevin and Soffa, Mary Lou and Whitehouse, Kamin},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Yang et al. - 2011 - Feasibility of Dynamic Binary Parallelization.pdf:pdf},
journal = {Usenix},
title = {{Feasibility of Dynamic Binary Parallelization}},
url = {http://www.cs.virginia.edu/~skadron/Papers/yang\_hotpar11.pdf},
year = {2011}
}
@article{Carter1979,
author = {Carter, J.Lawrence and Wegman, Mark N},
doi = {10.1016/0022-0000(79)90044-8},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
month = apr,
number = {2},
pages = {143--154},
title = {{Universal classes of hash functions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022000079900448},
volume = {18},
year = {1979}
}
@article{Park2005,
author = {Park, Laurence A. F. and Ramamohanarao, Kotagiri and Palaniswami, Marimuthu},
doi = {10.1145/1080343.1080345},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Park, Ramamohanarao, Palaniswami - 2005 - A novel document retrieval method using the discrete wavelet transform.pdf:pdf},
issn = {10468188},
journal = {ACM Transactions on Information Systems},
keywords = {Daubechies,Haar,document retrieval,multiresolution analysis,proximity search,vector space methods,wavelet transform},
month = jul,
number = {3},
pages = {267--298},
publisher = {ACM},
title = {{A novel document retrieval method using the discrete wavelet transform}},
url = {http://dl.acm.org/citation.cfm?id=1080343.1080345},
volume = {23},
year = {2005}
}
@inproceedings{PeytonJones2011,
address = {Melbourne},
author = {Peyton-Jones, Simon},
booktitle = {YOW},
publisher = {Presented at YOW 2011},
title = {{The Future is Parallel, and the Future of Parallel is Declarative}},
url = {http://yow.eventer.com/yow-2011-1004/the-future-is-parallel-and-the-future-of-parallel-is-declarative-by-simon-peyton-jones-1055},
year = {2011}
}
@article{Mainland2013,
author = {Mainland, Geoffrey and Leshchinskiy, Roman and Peyton-Jones, Simon},
doi = {2500365.2500601},
file = {:afs/inf.ed.ac.uk/user/s12/s1255753/Documents/\_mendeley/Mainland, Leshchinskiy, Peyton-Jones/ACM SIGPLAN International Conference on Functional Programming/Mainland, Leshchinskiy, Peyton-Jones - 2013 - Exploiting Vector Instructions with Generalized Stream Fusion - ACM SIGPLAN International.pdf:pdf},
isbn = {9781450323260},
journal = {ACM SIGPLAN International Conference on Functional Programming},
keywords = {12,15,23,29,30,34,8,allow some of these,ate structures to be,eliminated,f,finding more general rules,g,great deal of research,has been,haskell,intermedi-,map,map g,simd,stream fusion,such as map f,the subject of a,vectorization},
number = {Section 4},
title = {{Exploiting Vector Instructions with Generalized Stream Fusion}},
url = {http://research.microsoft.com/en-us/um/people/simonpj/papers/ndp/haskell-beats-C.pdf},
year = {2013}
}
@misc{Clarke2011,
author = {Clarke, Trent},
booktitle = {for fun() and profit},
month = oct,
title = {{Why Functional?}},
url = {http://forfunand.wordpress.com/2011/10/07/why-functional},
year = {2011}
}
@inproceedings{Patel,
abstract = {For a variety of reasons, branch-less regions of instructions are desirable for high-performance execution. In this paper we propose a means for increasing the dynamic length of branch-less regions of instructions for the purposes of dynamic program optimization. We call these atomic regions frames and we construct them by replacing original branch instructions with assertions. Assertion instructions check if the original branching conditions still hold. If they hold, no action is taken. If they do not, then the entire region is undone. In this manner an assertion has no explicit control flow. We demonstrate that using branch correlation to decide when a branch should be converted into an assertion results in atomic regions that average over 100 instructions in length, with a probability of completion of 97\%, and that constitute over 80\% of the dynamic instruction stream. We demonstrate both static and dynamic means for constructing frames. When frames are built dynamically using finite sized hardware, they average 80 instructions in length and have good caching properties},
author = {Patel, S.J. and Tung, T. and Bose, S. and Crum, M.M.},
booktitle = {Proceedings 33rd Annual IEEE/ACM International Symposium on Microarchitecture. MICRO-33 2000},
doi = {10.1109/MICRO.2000.898080},
isbn = {0-7695-0924-X},
pages = {303--313},
publisher = {IEEE},
title = {{Increasing the size of atomic instruction blocks using control flow assertions}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=898080}
}
@inproceedings{Sun2011,
abstract = {We propose a new approach that automatically parallelizes Java programs at runtime. The approach collects on-line trace information during program execution, and dynamically recompiles methods that can be executed in parallel. Wealso describe a cost/benefit model that makes intelligent parallelization decisions, as well as a parallel execution environment to execute parallelized code. We implement these techniques upon Jikes RVM and evaluate our approach by parallelizing sequential benchmarks and comparing the performance to manually parallelized version of those benchmarks. According to the experimental results, our approach has low overheads and achieves competitive speed-ups compared to manually parallelized code.},
author = {Sun, Yu and Zhang, Wei},
booktitle = {2011 15th Workshop on Interaction between Compilers and Computer Architectures},
doi = {10.1109/INTERACT.2011.11},
isbn = {978-1-4577-0834-3},
month = feb,
pages = {35--43},
publisher = {IEEE},
title = {{On-Line Trace Based Automatic Parallelization of Java Programs on Multicore Platforms}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5936720},
year = {2011}
}
@article{Kiczales1997,
abstract = {This position statement presents the concept of Aspect-Oriented Programming as a promising area of research in programming languages and software engineering.},
author = {Kiczales, Gregor},
doi = {10.1145/242224.242420},
isbn = {3540630899},
issn = {03600300},
journal = {ACM Computing Surveys},
month = dec,
number = {4es},
pages = {154--es},
pmid = {11346780},
title = {{Aspect-oriented programming}},
url = {http://portal.acm.org/citation.cfm?doid=242224.242420},
volume = {28},
year = {1996}
}
@article{Ghemawat2003,
author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
doi = {10.1145/1165389.945450},
isbn = {1-58113-757-5},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {clustered storage,data storage,fault tolerance,scalability},
month = dec,
number = {5},
pages = {29},
publisher = {ACM},
title = {{The Google file system}},
url = {http://dl.acm.org/citation.cfm?id=1165389.945450},
volume = {37},
year = {2003}
}
@incollection{Latorre2011,
author = {Latorre, F and Magklis, G and Gonz\'{a}lez, J},
booktitle = {Transactions on High-Performance Embedded Architectures and Compilers III},
doi = {10.1007/978-3-642-19448-1\_7},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Latorre, Magklis, Gonz\'{a}lez - 2011 - CROB implementing a large instruction window through compression.bin:bin},
isbn = {978-3-642-19447-4},
pages = {115--134},
publisher = {Springer Berlin Heidelberg},
title = {{CROB: implementing a large instruction window through compression}},
url = {http://www.springerlink.com/index/9371360L17X6240W.pdf},
year = {2011}
}
@article{Nayfeh1997,
abstract = {Presents the case for billion-transistor processor architectures that will consist of chip multiprocessors (CMPs): multiple (four to 16) simple, fast processors on one chip. In their proposal, each processor is tightly coupled to a small, fast, level-one cache, and all processors share a larger level-two cache. The processors may collaborate on a parallel job or run independent tasks (as in the SMT proposal). The CMP architecture lends itself to simpler design, faster validation, cleaner functional partitioning, and higher theoretical peak performance. However for this architecture to realize its performance potential, either programmers or compilers will have to make code explicitly parallel. Old ISAs will be incompatible with this architecture (although they could run slowly on one of the small processors)},
author = {Nayfeh, B.A. and Olukotun, K.},
doi = {10.1109/2.612253},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Nayfeh, Olukotun - 1997 - A single-chip multiprocessor.html:html},
issn = {00189162},
journal = {Computer},
number = {9},
pages = {79--85},
title = {{A single-chip multiprocessor}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=612253},
volume = {30},
year = {1997}
}
@inproceedings{Allan2005,
abstract = {Abc is an extensible, optimising compiler for AspectJ. It has been designed as a workbench for experimental research in aspect-oriented programming languages and compilers. We outline a programme of research in these areas, and we review how abc can help in achieving those research goals},
author = {Allan, Chris and Avgustinov, Pavel and Christensen, Aske Simon and Hendren, Laurie J and Kuzins, Sascha and Lhot\'{a}k, Jennifer and Lhot\'{a}k, Ondrej and {De Moor}, Oege and Sereni, Damien and Sittampalam, Ganesh and Tibble, Julian},
booktitle = {Generative Programming and Component Engineering 4th International Conference GPCE},
doi = {10.1007/11561347\_2},
isbn = {3540291385},
pages = {10--16},
title = {{abc: The AspectBench Compiler for AspectJ}},
volume = {3676},
year = {2005}
}
@techreport{Marshall2005,
address = {Santa Cruz},
author = {Marshall, Casey},
file = {:Users/chris/Library/Application Support/Mendeley Desktop/Downloaded/Marshall - 2005 - Software Transactional Memory.pdf:pdf},
institution = {University of California, Santa Cruz},
title = {{Software Transactional Memory}},
url = {http://www.cs.uic.edu/~ajayk/STM.pdf},
year = {2005}
}
@article{Dijkstra1968,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Dijkstra, Edsger W},
doi = {10.1145/362929.362947},
issn = {00010782},
journal = {Communications of the ACM},
month = mar,
number = {3},
pages = {147--148},
title = {{Letters to the editor: go to statement considered harmful}},
url = {http://portal.acm.org/citation.cfm?doid=362929.362947},
volume = {11},
year = {1968}
}
