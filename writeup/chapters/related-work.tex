\chapter{Related Work} \label{chp:related}
The idea of an automatic parallelising compiler is not a particularly new one, and indeed has been the focus of much research since the dawn of structured programming with Fortran \citep{Backus1979}.

In this chapter, some background of both parallelising compilers and parallelism detection will be presented. The areas have a rich and full history spanning many decades (indeed, the objective of automatic parallelising compilers has been sought for many years), so this is a somewhat brief introduction; only the major results are considered.

\section{Parallelising Compilers} \label{sec:related/compilers}
	
Programs and/or runtime systems are attractive because they require no access to the source code. In \citeyear{Yang2011}, \citet{Yang2011} introduced one of the main advances on the field, \textit{Dynamic Binary Parallelisation}. It requires no access to the source code, and instead operates only using object code. The mechanism through which it operates is by detecting hot loops -- loops where the program spends a majority of execution time -- and parallelises them, executing the parallel versions speculatively. This speculation is likely the cause of the inefficiencies of their approach - using 256 cores they achieved a somewhat negligible performance improvement of just 4.5 times. One of the advantages of the approach presented in this dissertation is that it does not require the use of speculative execution - a loop is only executed if it can be proven to contain no inter-iteration dependencies.
	
The main difference between \citeauthor{Yang2011}'s work and the work outlined here is the nature of the dynamic detection. \citeauthor{Yang2011} used dynamic trace analysis, which can only identify the hot loops within a program, and not whether the iterations within those loops have dependencies. The work presented in this dissertation \emph{does} determine whether there are inter-loop dependencies, therefore the use of speculative execution is not required. Although we have not yet done so, the addition of hot-loop detection would be a trivial addition to our framework.

\citet{Wang2009} used a technique called \textit{backwards slicing} \citep{Weiser} in order to preserve essential dependence and data flow. The advantage of an approach based on slicing is that it can detect parallelism regardless of the granularity. This is in contrast to the work presented in this 

\citet{Ketterlin}

\citet{Dong}

\section{Parallelism Detection} \label{sec:related/detection}