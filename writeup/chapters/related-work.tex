\chapter{Related Work} \label{chp:related}
\section{Parallelising Compilers} \label{sec:related/compilers}
The idea of an automatic parallelising compiler is not a particularly new one, and indeed has been the focus of much research since the dawn of structured programming with Fortran \citep{Backus1979}.
	
Programs and/or runtime systems are attractive because they require no access to the source code. In \citeyear{Yang2011}, \citet{Yang2011} introduced one of the main advances on the field, \textit{Dynamic Binary Parallelisation}. It requires no access to the source code, and instead operates only using object code. The mechanism through which it operates is by detecting hot loops -- loops where the program spends a majority of execution time -- and parallelises them, executing the parallel versions speculatively. This speculation is likely the cause of the inefficiencies of their approach - using 256 cores they achieved a somewhat negligible performance improvement of just 4.5 times. One of the advantages of the approach presented in this dissertation is that it does not require the use of speculative execution - a loop is only executed if it can be proven to contain no inter-iteration dependencies.
	
The main difference between \citeauthor{Yang2011}'s work and the work outlined here is the nature of the dynamic detection. \citeauthor{Yang2011} used dynamic trace analysis, which can only identify the hot loops within a program, and not whether the iterations within those loops have dependencies. The work presented in this dissertation \emph{does} determine whether there are inter-loop dependencies, therefore the use of speculative execution is not required. Although we have not yet done so, the addition of hot-loop detection would be a trivial addition to our framework.

\section{Parallelism Detection} \label{sec:related/detection}